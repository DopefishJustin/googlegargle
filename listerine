#!/bin/bash
#./listerine - a companion to the google gargle project
#relies on /proc/, googlegrape, aria2c, curl, and youtube-dl

# LietKynes fork
# This version runs googlegargle in parallel for situations like mine where I'm throttled at 80k per download, but I can have several in parallel. I don't know if google or my ISP does the throttling.
# By default this script runs 3 processes in parallel, but you can adjust the number in real-time like this:
# echo 30 > _max_concurrent
# To stop the script safely you should do this:
# echo 0 > _max_concurrent
# touch _stop
#


# Change the username below to something unique to you. ALPHANUMERIC ONLY!
if [ -f _username ]
then
	read USERNAME < _username
else
	echo "Write your username in the file _username, for example:"
	echo "echo PrinceAlbert > _username"
	exit;
fi
EXTERN_IP=`curl icanhazip.com` #Do not change without good reason, or underscor will eat your brains
SERVER=199.48.254.90:8081
RAN=0 #how many processes ran so far

mkdir -p _logs
mkdir -p _queue
curl -s http://$SERVER/introduce/$USERNAME/$EXTERN_IP
echo ""
while true
do
	
	RUNNING=10
	MAX=1
	while [ $RUNNING -ge $MAX ]
	do
		if [ -f ./_max_concurrent ]
		then
			read MAX < ./_max_concurrent
		else
			MAX=3
		fi;
		echo "Max downloads in parallel: $MAX"
		RUNNING=0
		for PID in $(jobs -p)
		do
			if [ -d /proc/$PID ] #TODO: (someone else) modify this for cross-platform
			then
				let "RUNNING = $RUNNING + 1"
			fi
		done
		echo "There are now $RUNNING jobs in the background."
		echo "PIDs:"; echo $(jobs -p)
		echo "IDs:"; ls _queue
		if [ -f _stop ]
		then
			break
		fi
		sleep 5;
	done
	
	if [ -f _stop ]
	then
		echo "_stop file found, waiting for child processes to end:"
		jobs
		wait
	else
		echo "Getting an id from $SERVER, authenticated as $USERNAME with IP $EXTERN_IP"
		id=`curl http://$SERVER/getID/$USERNAME | sed "s/[^0-9\\-]//g"`

		echo ID is $id
		./googlegargle -- "$id" 1>>_logs/"$id".log 2>&1 &
		touch _queue/"$id"

		echo "Started googlegargle for $id - $! - in background"
		let "RAN = $RAN + 1"
	fi

	#use the commented 'for' line to report files you've downloaded separately using older versions
	#if the serverkeeper supports this.
	#for id in $(find 0/ 1/ 2/ 3/ 4/ 5/ 6/ 7/ 8/ 9/ -name \*flv | sed 's#.*/##g;s/.flv//g')	
	for id in $(ls _queue/)
	do
		SEPDIB=$(echo "$id" | sed 's/-//g' | cut -c1)
		SECDIB=$(echo "$id" | sed 's/-//g' | cut -c2)
		THIRDIB=$(echo "$id" | sed 's/-//g' | cut -c3)
		if [ -f "$SEPDIB/$SECDIB/$THIRDIB/$id/$id.flv.aria2" ]
		then
			echo "NOT finished yet: $id"
		elif [ -f "$SEPDIB/$SECDIB/$THIRDIB/$id/$id.flv" ]
		then
			hash=`sha1sum "$SEPDIB/$SECDIB/$THIRDIB/$id/$id.flv"|awk '{print $1}'`
			size=`du -b "$SEPDIB/$SECDIB/$THIRDIB/$id/$id.flv"|awk '{print $1}'`
			echo "http://$SERVER/finishVid/$USERNAME/$id/$size/$hash"
			curl "http://$SERVER/finishVid/$USERNAME/$id/$size/$hash" && rm -f _queue/"$id"
		else
			echo "Just started, no files written yet: $id"
		fi
	done
	if [ -f _stop ]
	then
		echo "_stop file found, exiting"
		break
	fi
done
echo "Ran a total of $RAN downloads"
